{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "2.1Prediction1Dregression_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cKN_kvOPtk-x",
        "E49F8e23tk-x"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV2ocDsqtk-M"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_f04RJhtk-W"
      },
      "source": [
        "<h1>Linear Regression 1D: Prediction</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TIw2hoXtk-X"
      },
      "source": [
        "<h2>Objective</h2><ul><li> How to make the prediction for multiple inputs.</li><li> How to use linear class to build more complex models.</li><li> How to build a custom module.</li></ul> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qQLOA92tk-Y"
      },
      "source": [
        "<h2>Table of Contents</h2>\n",
        "<p>In this lab, we will  review how to make a prediction in several different ways by using PyTorch.</h2>\n",
        "<ul>\n",
        "    <li><a href=\"#Prediction\">Prediction</a></li>\n",
        "    <li><a href=\"#Linear\">Class Linear</a></li>\n",
        "    <li><a href=\"#Cust\">Build Custom Modules</a></li>\n",
        "</ul>\n",
        "<p>Estimated Time Needed: <strong>15 min</strong></p>\n",
        "\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mTSR4tntk-Y"
      },
      "source": [
        "<h2>Preparation</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrGZNxrntk-Z"
      },
      "source": [
        "The following are the libraries we are going to use for this lab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOSt9rbQtk-Z"
      },
      "source": [
        "# These are the libraries will be used for this lab.\n",
        "\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_CAEd7Gtk-a"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNDQyCZ_tk-a"
      },
      "source": [
        "<h2 id=\"Prediction\">Prediction</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgv8GssTtk-b"
      },
      "source": [
        "Let us create the following expressions:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMyUxIgctk-b"
      },
      "source": [
        "$b=-1,w=2$\n",
        "\n",
        "$\\hat{y}=-1+2x$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk46GyuQtk-b"
      },
      "source": [
        "First, define the parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suSrwgb0tk-c"
      },
      "source": [
        "# Define w = 2 and b = -1 for y = wx + b\n",
        "\n",
        "w = torch.tensor(2.0, requires_grad = True)\n",
        "b = torch.tensor(-1.0, requires_grad = True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mx3fvpJtk-c"
      },
      "source": [
        "Then, define the function <code>forward(x, w, b)</code> makes the prediction: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHxjNst2tk-c"
      },
      "source": [
        "# Function forward(x) for prediction\n",
        "\n",
        "def forward(x):\n",
        "    yhat = w * x + b\n",
        "    return yhat"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfCTN3TMtk-d"
      },
      "source": [
        "Let's make the following prediction at <i>x = 1</i>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIOlb6MHtk-d"
      },
      "source": [
        "$\\hat{y}=-1+2x$\n",
        "\n",
        "$\\hat{y}=-1+2(1)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e69AYaWltk-d",
        "outputId": "0008813b-a9e9-497a-c1f5-a81f8be9d90e"
      },
      "source": [
        "# Predict y = 2x - 1 at x = 1\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[1.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRx6_9DHtk-e"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m69L4VGUtk-e"
      },
      "source": [
        "Now, let us try to make the prediction for multiple inputs:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuwQQLyItk-e"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter2/2.1.2.png\" width=\"500\" alt=\"Linear Regression Multiple Input Samples\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLlHCF5Ttk-e"
      },
      "source": [
        "Let us construct the <code>x</code> tensor first. Check the shape of <code>x</code>.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nafVAW2Otk-f",
        "outputId": "cc582a12-e51d-4270-f6dd-e8a6c6e0dc11"
      },
      "source": [
        "# Create x Tensor and check the shape of x tensor\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "print(\"The shape of x: \", x.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of x:  torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_8oFulmtk-f"
      },
      "source": [
        "Now make the prediction: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRn5dxE5tk-f",
        "outputId": "6898f040-afcf-4348-de81-410c2091d94d"
      },
      "source": [
        "# Make the prediction of y = 2x - 1 at x = [1, 2]\n",
        "\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[1.],\n",
            "        [3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxHbiPCZtk-g"
      },
      "source": [
        "The result is the same as what it is in the image above.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OboOJ0BGtk-g"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK-S0FB0tk-g"
      },
      "source": [
        "<h3>Practice</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVDuUFGstk-g"
      },
      "source": [
        "Make a prediction of the following <code>x</code> tensor using the <code>w</code> and <code>b</code> from above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G467CBBhtk-h",
        "outputId": "64656dd1-4b99-40b2-d58a-37612ffe398a"
      },
      "source": [
        "# Practice: Make a prediction of y = 2x - 1 at x = [[1.0], [2.0], [3.0]]\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[1.],\n",
            "        [3.],\n",
            "        [5.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTNHnZrvtk-h"
      },
      "source": [
        "Double-click <b>here</b> for the solution.\n",
        "\n",
        "<!-- Your answer is below:\n",
        "yhat = forward(x)\n",
        "print(\"The prediction: \", yhat)\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f_Oau9qtk-h"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIn8OItjtk-h"
      },
      "source": [
        "<h2 id=\"Linear\">Class Linear</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi0hhq4Dtk-i"
      },
      "source": [
        "The linear class can be used to make a prediction. We can also use the linear class to build more complex models. Let's import the module:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEApsNbztk-i"
      },
      "source": [
        "# Import Class Linear\n",
        "\n",
        "from torch.nn import Linear"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hljm99i-tk-i"
      },
      "source": [
        "Set the random seed because the parameters are randomly initialized:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5fvigwVtk-i",
        "outputId": "c54273ac-74ba-444d-ba89-bcb4863ce4a3"
      },
      "source": [
        "# Set random seed\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0cc35b1930>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8h0vGrttk-j"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkR_xFMhtk-j"
      },
      "source": [
        "Let us create the linear object by using the constructor. The parameters are randomly created. Let us print out to see what <i>w</i> and <i>b</i>. The parameters of an <code>torch.nn.Module</code> model are contained in the model’s parameters accessed with <code>lr.parameters()</code>:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3U8fEi_tk-k",
        "outputId": "d46e3055-b144-4d6d-a59d-a56fcf9d84c2"
      },
      "source": [
        "# Create Linear Regression Model, and print out the parameters\n",
        "\n",
        "lr = Linear(in_features=1, out_features=1, bias=True)\n",
        "print(\"Parameters w and b: \", list(lr.parameters()))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters w and b:  [Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3bhtmijtk-k"
      },
      "source": [
        "This is equivalent to the following expression:  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJX6r1Eitk-k"
      },
      "source": [
        "$b=-0.44, w=0.5153$\n",
        "\n",
        "$\\hat{y}=-0.44+0.5153x$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiRFg0Y8tk-k"
      },
      "source": [
        "A method  <code>state_dict()</code> Returns a Python dictionary object corresponding to the layers of each parameter  tensor. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb3QjsF4tk-l",
        "outputId": "b28df5d4-127c-4607-c037-ad99393e0b1e"
      },
      "source": [
        "print(\"Python dictionary: \",lr.state_dict())\n",
        "print(\"keys: \",lr.state_dict().keys())\n",
        "print(\"values: \",lr.state_dict().values())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python dictionary:  OrderedDict([('weight', tensor([[0.5153]])), ('bias', tensor([-0.4414]))])\n",
            "keys:  odict_keys(['weight', 'bias'])\n",
            "values:  odict_values([tensor([[0.5153]]), tensor([-0.4414])])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU3Sdeijtk-l"
      },
      "source": [
        "The keys correspond to the name of the attributes and the values correspond to the parameter value.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q12gBVM2tk-l",
        "outputId": "1fecd544-4108-45d7-fd5d-2b59e867a55e"
      },
      "source": [
        "print(\"weight:\",lr.weight)\n",
        "print(\"bias:\",lr.bias)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight: Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True)\n",
            "bias: Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9I3Enmotk-m"
      },
      "source": [
        "Now let us make a single prediction at <i>x = [[1.0]]</i>.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgCHZbH2tk-m",
        "outputId": "87629deb-1141-48f3-9eb4-c6e33433f961"
      },
      "source": [
        "# Make the prediction at x = [[1.0]]\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.0739]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Tw7tLaktk-m"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TqFHRWctk-m"
      },
      "source": [
        "Similarly, you can make multiple predictions:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1QzQ8P1tk-n"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter2/2.1.2vector_function.png\" width=\"500\" alt=\"Linear Class Sample with Multiple Inputs\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uecsuINRtk-n"
      },
      "source": [
        "Use model <code>lr(x)</code> to predict the result.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rkYHP57tk-n",
        "outputId": "8ce6fa83-9931-460c-f66d-f2eb25848ca3"
      },
      "source": [
        "# Create the prediction using linear model\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.0739],\n",
            "        [0.5891]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr5zBalbtk-n"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjt-0smrtk-o"
      },
      "source": [
        "<h3>Practice</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-t6mH-3tk-o"
      },
      "source": [
        "Make a prediction of the following <code>x</code> tensor using the linear regression model <code>lr</code>.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv89dnDltk-o",
        "outputId": "a7aa4cc8-4151-47a8-b253-c89436fe371b"
      },
      "source": [
        "# Practice: Use the linear regression model object lr to make the prediction.\n",
        "\n",
        "x = torch.tensor([[1.0],[2.0],[3.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.0739],\n",
            "        [0.5891],\n",
            "        [1.1044]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r02gA8X4tk-o"
      },
      "source": [
        "Double-click <b>here</b> for the solution.\n",
        "\n",
        "<!-- Your answer is below:\n",
        "x=torch.tensor([[1.0],[2.0],[3.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHCdge42tk-p"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0dP5A7ftk-p"
      },
      "source": [
        "<h2 id=\"Cust\">Build Custom Modules</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlwjHtXktk-p"
      },
      "source": [
        "Now, let's build a custom module. We can make more complex models by using this method later on. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZccQyh6tk-p"
      },
      "source": [
        "First, import the following library.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFHQRNS7tk-q"
      },
      "source": [
        "# Library for this section\n",
        "\n",
        "from torch import nn"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOg0Vl_2tk-q"
      },
      "source": [
        "Now, let us define the class: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq-K6hvktk-q"
      },
      "source": [
        "# Customize Linear Regression Class\n",
        "\n",
        "class LR(nn.Module):\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self, input_size, output_size):\n",
        "        \n",
        "        # Inherit from parent\n",
        "        super(LR, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "    \n",
        "    # Prediction function\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsuNPC4rtk-r"
      },
      "source": [
        "Create an object by using the constructor. Print out the parameters we get and the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIwoHFrqtk-r",
        "outputId": "908cc5e5-ae50-4c11-84c6-8f6bb26315e7"
      },
      "source": [
        "# Create the linear regression model. Print out the parameters.\n",
        "\n",
        "lr = LR(1, 1)\n",
        "print(\"The parameters: \", list(lr.parameters()))\n",
        "print(\"Linear model: \", lr.linear)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters:  [Parameter containing:\n",
            "tensor([[-0.1939]], requires_grad=True), Parameter containing:\n",
            "tensor([0.4694], requires_grad=True)]\n",
            "Linear model:  Linear(in_features=1, out_features=1, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulNBgckZtk-r"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC5SpOsCtk-s"
      },
      "source": [
        "Let us try to make a prediction of a single input sample.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4TEEEX5tk-s",
        "outputId": "c059051b-3140-48a8-f760-842505570165"
      },
      "source": [
        "# Try our customize linear regression model with single input\n",
        "\n",
        "x = torch.tensor([[1.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.2755]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtaEBVWVtk-s"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRVlZQKYtk-s"
      },
      "source": [
        "Now, let us try another example with multiple samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yakNXFWLtk-s",
        "outputId": "f5a4ec56-2aa0-419d-e090-f0a6cfcb185f"
      },
      "source": [
        "# Try our customize linear regression model with multiple input\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0]])\n",
        "yhat = lr(x)\n",
        "print(\"The prediction: \", yhat)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction:  tensor([[0.2755],\n",
            "        [0.0816]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHKnze6vtk-t"
      },
      "source": [
        "the parameters are also stored in an ordered dictionary :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16u1naqQtk-t",
        "outputId": "f575c014-e646-41e5-a4b1-cf0ed6dc119e"
      },
      "source": [
        "print(\"Python dictionary: \", lr.state_dict())\n",
        "print(\"keys: \",lr.state_dict().keys())\n",
        "print(\"values: \",lr.state_dict().values())\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python dictionary:  OrderedDict([('linear.weight', tensor([[-0.1939]])), ('linear.bias', tensor([0.4694]))])\n",
            "keys:  odict_keys(['linear.weight', 'linear.bias'])\n",
            "values:  odict_values([tensor([[-0.1939]]), tensor([0.4694])])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw-PSYGjtk-t"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gczGX_FCtk-t"
      },
      "source": [
        "<h3>Practice</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgVInG0wtk-u"
      },
      "source": [
        "Create an object <code>lr1</code> from the class we created before and make a prediction by using the following tensor: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvbKB8KItk-u",
        "outputId": "ab4e9396-71e0-44e6-a2b7-31e40988d1e9"
      },
      "source": [
        "# Practice: Use the LR class to create a model and make a prediction of the following tensor.\n",
        "\n",
        "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
        "lr1=LR(1,1)\n",
        "yhat=lr(x)\n",
        "yhat"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2755],\n",
              "        [ 0.0816],\n",
              "        [-0.1122]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id3ToLYNtk-u"
      },
      "source": [
        "Double-click <b>here</b> for the solution.\n",
        "\n",
        "<!-- Your answer is below:\n",
        "x=torch.tensor([[1.0],[2.0],[3.0]])\n",
        "lr1=LR(1,1)\n",
        "yhat=lr(x)\n",
        "yhat\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUNFg5rKtk-v"
      },
      "source": [
        " <!-- Your answer is below:\n",
        "x=torch.tensor([[1.0],[2.0],[3.0]])\n",
        "lr1=LR(1,1)\n",
        "yhat=lr1(x)\n",
        "yhat\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcXNqWsxtk-v"
      },
      "source": [
        "<a href=\"https://dataplatform.cloud.ibm.com/registration/stepone?context=cpdaas&apps=data_science_experience,watson_machine_learning\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH2qI5d3tk-w"
      },
      "source": [
        "<h2>About the Authors:</h2> \n",
        "\n",
        "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hwiubRStk-w"
      },
      "source": [
        "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKN_kvOPtk-x"
      },
      "source": [
        "## Change Log\n",
        "\n",
        "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                          |\n",
        "| ----------------- | ------- | ---------- | ----------------------------------------------------------- |\n",
        "| 2020-09-21        | 2.0     | Shubham    | Migrated Lab to Markdown and added to course repo in GitLab |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiubzoB4tk-x"
      },
      "source": [
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E49F8e23tk-x"
      },
      "source": [
        "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
      ]
    }
  ]
}